## Задача 1 - solar_flare_nbc.py

Дадено ни е податочно множество за соларен одблесок. Сите атрибути кои ги содржи се од категориски тип (последната
колона е класен атрибут). Ваша задача е да истренирате наивен баесов класификатор кој ќе предвидува класи на соларен
одблесок користејќи ги првите 75% од даденото податочно множество. Треба да ја пресметате точноста која ја добивате над
останатите 25% од податочното множество и потоа да направите предвидувања на записи кои ги примате на влез.

Во почетниот код имате дадено податочно множество. На влез се прима еден запис за кој треба да се направи предвидување
на класата. На излез треба да се испечати точноста на моделот, класата на предвидување како и веројатностите за
припадност во класите.

````
Input
H R X 1 2 1 1 2 1 1

Expected
0.8294797687861272
0
[[9.94855050e-01 4.57710457e-03 3.71407825e-04 9.29521929e-05
  3.34611214e-05 3.36218889e-05 7.71205438e-06 2.86906785e-05]]
----------
Input
B X O 1 1 1 1 2 1 1

Expected
0.8294797687861272
0
[[9.88572334e-01 1.01920479e-02 4.42791737e-05 3.79945496e-04
  6.38276614e-05 5.77208953e-04 8.82652539e-05 8.20919400e-05]]
----------
Input
D S I 1 3 1 1 2 1 1

Expected
0.8294797687861272
0
[[7.99283134e-01 1.72371074e-01 2.11878009e-02 6.49306341e-03
  2.33738631e-04 3.13148870e-04 9.57717803e-05 2.22683641e-05]]
----------
Input
D S O 1 3 1 1 2 1 1

Expected
0.8294797687861272
0
[[8.81252701e-01 1.11789067e-01 4.96205620e-03 1.68959623e-03
  3.64934592e-05 2.20012775e-04 4.48583559e-05 5.21511764e-06]]
----------
Input
E K C 2 2 2 2 2 2 1

Expected
0.8294797687861272
6
[[4.70519907e-05 2.15579907e-02 1.77284820e-01 1.10712972e-01
  2.76325803e-01 4.62755733e-02 3.18435177e-01 4.93606115e-02]]
----------
Input
E A I 1 3 1 2 2 1 1

Expected
0.8294797687861272
0
[[3.29648050e-01 1.80093013e-01 2.90324658e-01 1.40129071e-01
  4.80418579e-02 8.58180979e-03 2.95269180e-03 2.28848261e-04]]
----------
Input
D R I 1 3 1 1 2 1 1

Expected
0.8294797687861272
0
[[8.36436895e-01 1.32606282e-01 2.44498869e-02 5.61955439e-03
  4.04587746e-04 3.61361450e-04 8.28876439e-05 3.85452213e-05]]
````

## Задача 2 - cryotherapy_nbc.py

Дадено ни е податочно множество за третмани со криотерапија. Сите атрибути кои ги содржи се од непрекинат тип и може да
се претпостави дека имаат непрекината распределба. Ваша задача е да истренирате наивен баесов класификатор кој ќе
предвидува дали терапијата е успешна или не (1 и 0) користејќи ги првите 85% од даденото податочно множество. Треба да
ја пресметате точноста која ја добивате над останатите 15% од податочното множество и потоа да направите предвидувања на
записи кои ги примате на влез.

Во почетниот код имате дадено податочно множество. На влез се прима еден запис за кој треба да се направи предвидување
на класата. На излез треба да се испечати точноста на моделот, класата на предвидување како и веројатностите за
припадност во класите.

````
Input
1 20 4 3 1 6

Expected
0.9285714285714286
1
[[0.0025448 0.9974552]]
----------
Input
1 34 11.25 1 3 150

Expected
0.9285714285714286
0
[[0.9964126 0.0035874]]
----------
Input
2 21 10.75 7 1 35

Expected
0.9285714285714286
1
[[0.15457656 0.84542344]]
----------
Input
2 41 7.75 5 2 20

Expected
0.9285714285714286
0
[[0.77477884 0.22522116]]
````

## Задача 3 - solar_flare_dtc.py

Дадено ни е податочно множество за соларен одблесок. Сите атрибути кои ги содржи се од категориски тип. Ваша задача е да
истренирате класификатор - дрво на одлука кој ќе предвидува класи на соларен одблесок користејќи ги последните X% од
даденото податочно множество. Треба да ја пресметате точноста која ја добивате над останатите (100 - X)% од податочното
множество.

Во почетниот код имате дадено податочно множество. На влез се прима вредност за процентот на поделба X. На пример, ако
вредноста е 80 значи дека ги користите последните 80% од множеството за тренирање, а првите 20% за тестирање.
Дополнително во променливата criterion се вчитува вредност за критериумот за избор на најдобар атрибут.

На излез треба да се испечати точност, длабочина и број на листови на изграденото дрво, како и карактеристиките со
најголема и најмала важност.

За да ги добиете истите резултати како и во тест примерите, при креирање на класификаторот поставете random_state=0

````
Input	
50
entropy

Expected
Depth: 12
Number of leaves: 125
Accuracy: 0.7771345875542692
Most important feature: 0
Least important feature: 9
----------
Input
50
gini

Expected
Depth: 12
Number of leaves: 122
Accuracy: 0.7916063675832128
Most important feature: 1
Least important feature: 9
----------
Input
60
entropy

Expected
Depth: 12
Number of leaves: 137
Accuracy: 0.7554347826086957
Most important feature: 2
Least important feature: 9
----------
Input
60
gini

Expected
Depth: 14
Number of leaves: 137
Accuracy: 0.7681159420289855
Most important feature: 2
Least important feature: 9
----------
Input
70
entropy

Expected
Depth: 13
Number of leaves: 162
Accuracy: 0.8164251207729468
Most important feature: 0
Least important feature: 9
----------
Input
70
gini

Expected
Depth: 14
Number of leaves: 169
Accuracy: 0.8067632850241546
Most important feature: 2
Least important feature: 9
----------
Input
80
entropy

Expected
Depth: 13
Number of leaves: 200
Accuracy: 0.8478260869565217
Most important feature: 0
Least important feature: 7
----------
Input
80
gini

Expected
Depth: 15
Number of leaves: 194
Accuracy: 0.8188405797101449
Most important feature: 2
Least important feature: 7
----------
Input
90
entropy

Expected
Depth: 12
Number of leaves: 231
Accuracy: 0.7391304347826086
Most important feature: 0
Least important feature: 7
----------
Input
90
gini

Expected
Depth: 14
Number of leaves: 228
Accuracy: 0.8188405797101449
Most important feature: 1
Least important feature: 7
````

## Задача 4 - fish_classification_rfc.py

Дадено ни е податочно множество за карактеристики на риби. Сите атрибути кои ги содржи се од непрекинат тип. Ваша задача
е да истренирате класификатор - колекција од дрва на одлука кој ќе предвидува класи на тип на риби користејќи ги првите
85% од даденото податочно множество. Треба да ја пресметате точноста која ја добивате над останатите 15% од податочното
множество. Притоа, се користи дел од множеството во кој е отстранета колоната col_index.

Во почетниот код имате дадено податочно множество. На влез се прима индекс на колоната која треба да се отстрани
col_index. Дополнително се вчитува бројот на дрва на одлука кои ќе се користат и вредност за критериумот за избор на
најдобар атрибут. На крај, се вчитува нов запис кој треба да се класифицира со тренираниот класификатор.

На излез треба да се испечати точност на класификаторот, предвидената класа за новиот запис и веројатностите за
припадност во класите.

Напомена: бидејќи вредностите се од непрекинат тип, нема потреба да ги претворите во целобројни вредности.

За да ги добиете истите резултати како и во тест примерите, при креирање на класификаторот поставете random_state=0.

````
Input	
1
10
entropy
10 21 32 50 40 10

Expected
Accuracy: 0.7916666666666666
Bream
[0.6 0.  0.2 0.  0.1 0.1 0. ]
----------
Input
1
10
gini
10 21 32 50 40 10

Expected
Accuracy: 0.8333333333333334
Bream
[0.5 0.  0.1 0.  0.3 0.1 0. ]
----------
Input
1
100
entropy
10 21 32 50 40 10

Expected
Accuracy: 0.7916666666666666
Bream
[0.54 0.   0.26 0.   0.1  0.1  0.  ]
----------
Input
1
100
gini
10 21 32 50 40 10

Expected
Accuracy: 0.75
Bream
[0.57 0.02 0.12 0.07 0.11 0.11 0.  ]
----------
Input
5
10
entropy
10 21 32 50 40 10

Expected
Accuracy: 0.75
Bream
[0.7 0.  0.  0.2 0.1 0.  0. ]
----------
Input
5
10
gini
10 21 32 50 40 10

Expected
Accuracy: 0.75
Bream
[0.8 0.  0.  0.1 0.1 0.  0. ]
----------
Input
5
100
entropy
10 21 32 50 40 10

Expected
Accuracy: 0.75
Bream
[0.66 0.03 0.08 0.05 0.15 0.01 0.02]
----------
Input
5
100
gini
10 21 32 50 40 10

Expected
Accuracy: 0.75
Bream
[0.62 0.   0.05 0.06 0.17 0.09 0.01]
----------
Input
3
150
entropy
10 21 32 50 40 10

Expected
Accuracy: 0.7916666666666666
Bream
[0.34       0.02       0.17333333 0.01333333 0.24666667 0.20666667
 0.        ]
----------
Input
3
150
gini
10 21 32 50 40 10

Expected
Accuracy: 0.75
Bream
[0.34       0.03333333 0.06666667 0.04666667 0.32666667 0.18666667
 0.        ]
````

## Задача 5 - solar_flare_nn_mlpc.py

Преголемо прилагодување (overfitting) претставува грешка на моделирање која се случува кога дадена функција е премногу
прилагодена на лимитирано множество на податочни инстанци. Преголемото прилагодување на моделот најчесто се појавува
кога имаме изградено прекомплексен модел за да се моделираат податоците кои ги проучуваме.

Дадено е податочно множество за класификација на соларните сигнали. Задачата е да се истренира невронска мрежа која ќе
ги разликува соларните сигнали одбиени од метален цилиндар и оние одбиени од цилиндрични карпи. Податочното множество се
состои од 15 карактеристики и две класи. Невронската мрежа потребно е да содржи 6 неврони во скриениот слој, активирани
со tanh активациската функција. Бројот на епохи (epoch_num) и ратата на учење (learning_rate) потребни за тренирање на
мрежата се читаат од стандарден влез.

Податочното множество поделете го на множество за тренирање и множество за валидација, во сооднос 80% : 20% од секоја од
класите, односно првите 80% од конкретна класа влегуваат во тренирачкото множество, а следните 20% се дел од
валидациското множество.

Потребно е да се детектира дали со зададените параметри за тренирање на моделот на невронска мрежа се случува преголемо
прилагодување (overfitting) на мрежата спрема тренирачкото множество. Доколку точноста која се добива со тренирачкото
множество е поголема за 15% од точноста добиена со валидациско множество, тогаш детектираме дека моделот прави
overfitting, односно премногу се прилагодува кон тренирачкото множество. Точноста на моделот со дадено множество се
пресметува преку формулата accuracy=predicted_correct/total, каде што predicted_correct претставува број на точно
предвидени инстанци, додека total е број на сите инстанци во множеството (точно и неточно предвидени).

Потребно е на стандарден излез да се испечати дали се случува overfitting или не (Se sluchuva overfitting/Ne se sluchuva
overfitting), по што се печати точноста добиена со тренирачкото множество и точноста со валидациското множество.

````
For example:
Input
0.1
300

Result
Se sluchuva overfitting
Tochnost so trenirachko mnozhestvo: 1.0
Tochnost so validacisko mnozhestvo: 0.46511627906976744
----------
Input
0.005
300

Expected
Se sluchuva overfitting
Tochnost so trenirachko mnozhestvo: 0.793939393939394
Tochnost so validacisko mnozhestvo: 0.6511627906976745
----------
Input
0.0004
300

Expected
Se sluchuva overfitting
Tochnost so trenirachko mnozhestvo: 0.7515151515151515
Tochnost so validacisko mnozhestvo: 0.6511627906976745
----------
Input
0.002
5

Expected
Ne se sluchuva overfitting
Tochnost so trenirachko mnozhestvo: 0.5333333333333333
Tochnost so validacisko mnozhestvo: 0.5348837209302325
----------
Input
0.05
70

Expected
Se sluchuva overfitting
Tochnost so trenirachko mnozhestvo: 0.8121212121212121
Tochnost so validacisko mnozhestvo: 0.6744186046511628
----------
Input
0.000002
70

Expected
Ne se sluchuva overfitting
Tochnost so trenirachko mnozhestvo: 0.5333333333333333
Tochnost so validacisko mnozhestvo: 0.5348837209302325
----------
Input
0.005
6

Expected
Ne se sluchuva overfitting
Tochnost so trenirachko mnozhestvo: 0.593939393939394
Tochnost so validacisko mnozhestvo: 0.5813953488372093
----------
Input
0.009
75

Expected
Se sluchuva overfitting
Tochnost so trenirachko mnozhestvo: 0.7575757575757576
Tochnost so validacisko mnozhestvo: 0.627906976744186
----------
Input
0.15
79

Expected
Se sluchuva overfitting
Tochnost so trenirachko mnozhestvo: 0.8242424242424242
Tochnost so validacisko mnozhestvo: 0.6744186046511628
----------
Input
0.009
10

Expected
Ne se sluchuva overfitting
Tochnost so trenirachko mnozhestvo: 0.7636363636363637
Tochnost so validacisko mnozhestvo: 0.6744186046511628
````

## Задача 6 - solar_flare_formula_dtc.py

Дадено ни е податочно множество за соларен одблесок. Сите атрибути кои ги содржи се од категориски тип. Ваша задача е да
истренирате класификатор - дрво на одлука кој ќе предвидува класи на соларен одблесок. Од стандарден влез се чита бројот
на примероци X за кои треба да се направи предвидувањето. Последните X примероци се земаат за тестирање, додека сите
останати примероци се за тренирање (на пр. ако X=6, последните 6 примероци се тест примероци, а останатите примероци се
дел од тренирачкото множество).

Во почетниот код имате дадено податочно множество, како и објект од моделот DecisionTreeClassifier. Ваша задача е да го
поделите првичното податочно множество на множество за тренирање и множество за тестирање. Потоа, истренирајте го
моделот. Пресметајте точност и прецизност на моделот со тестирачкото множество и вредностите испечатете ги на стандарден
излез. Напомена: Освен тоа што се бара не е потребно да имплементирате ништо друго!

точност = (TP + TN) / (TP + FP + TN + FN)
прецизност = TP / (TP + FP)

TP - број на точно предвидени позитивни класи

FP - број на грешно предвидени позитивни класи

TN - број на точно предвидени негативни класи

FN - број на грешно предвидени негативни класи

ЗАБЕЛЕШКА: Ако TP + FP е 0, тогаш вредноста за прецизноста е 0.

За да ги добиете истите резултати како и во тест примерите, при креирање на класификаторот поставете random_state=0

````
For example:
Input
10

Result
Accuracy: 0.6
Precision: 0.0
----------
Input
15

Result
Accuracy: 0.6666666666666666
Precision: 0.0
----------
Input
20

Result
Accuracy: 0.7
Precision: 0.0
----------
Input
50

Result
Accuracy: 0.8
Precision: 0.2
----------
Input
1

Result
Accuracy: 1.0
Precision: 0.0
````

## Задача 7 - solar_flare_nbc_dtc_mlpc.py

Дадено е податочно множество за класификација на соларни сигнали, кое се состои од 15 карактеристики и две класи.

Потребно е да направите 3 модели на класификација:

* Наивен баесов класификатор.

* Класификатор со колекција од 50 дрва на одлука со ентропија како критериум за избор на најдобар атрибут за поделба.

* Невронска мрежа со 50 неврони, ReLU активациска функција, 0.001 рата на учење.

Од стандарден влез прво се чита критериум (mode) за поделба на подмножества за тренирање и тестирање, а потоа и
процент (split) за поделба. Ако критериумот за поделба е "balanced" тогаш потребно е да го поделите податочното
множество така што за тренирање ќе ги користите првите split% од секоја класа, а останатите за тестирање. Во спротивно,
ако критериумот за поделба не е "balanced" тогаш потребно е да го поделите податочното множество така што за тренирање
ќе ги користите првите split% од множеството, а останатите за тестирање.

Да се испечати точноста на моделот кој има највисока прецизност.

прецизност = TP / (TP + FP)

одзив = TP / (TP + FN)

TP - број на точно предвидени позитивни класи

FP - број на грешно предвидени позитивни класи

TN - број на точно предвидени негативни класи

FN - број на грешно предвидени негативни класи

````
For example:
Input
balanced
50

Result
Najvisoka preciznost ima prviot klasifikator
Negovata tochnost e: 0.47619047619047616
----------
Input
not balanced
50

Result
Najvisoka preciznost ima prviot klasifikator
Negovata tochnost e: 0.23076923076923078
----------
Input
balanced
60

Result
Najvisoka preciznost ima vtoriot klasifikator
Negovata tochnost e: 0.5476190476190477
----------
Input
not balanced
60

Result
Najvisoka preciznost ima prviot klasifikator
Negovata tochnost e: 0.16666666666666666
----------
Input
balanced
70

Result
Najvisoka preciznost ima vtoriot klasifikator
Negovata tochnost e: 0.703125
----------
Input
not balanced
70

Result
Najvisoka preciznost ima prviot klasifikator
Negovata tochnost e: 0.20634920634920634
----------
Input
balanced
80

Result
Najvisoka preciznost ima vtoriot klasifikator
Negovata tochnost e: 0.6744186046511628
----------
Input
not balanced
80

Result
Najvisoka preciznost ima prviot klasifikator
Negovata tochnost e: 0.2857142857142857
----------
Input
balanced
40

Result
Najvisoka preciznost ima prviot klasifikator
Negovata tochnost e: 0.5158730158730159
----------
Input
not balanced
40

Result
Najvisoka preciznost ima prviot klasifikator
Negovata tochnost e: 0.112
````

## Задача 8 - solar_flare_cross_validation_nbc_vs_nn_mlpc.py

Дадено е податочно множество за класификација на соларни сигнали, кое се состои од 15 карактеристики и две класи.

Потребно е да направите евалуација на модел на класификација преку методот на крос валидација. За таа цел, поделете го
податочното множество на 4 подмножества:

П1: подмножество кое ги содржи првата четвртина од примероците од секоја класа

П2: подмножество кое ги содржи втората четвртина од примероците од секоја класа

П3: подмножество кое ги содржи третата четвртина од примероците од секоја класа

П4: подмножество кое ги содржи последната четвртина од примероците од секоја класа

Потоа, извршете 4 чекори на тренирање на класификаторот така што секое подмножество еднаш ќе се користи за тестирање, а
останатите 3 за тренирање. На пример: во првиот чекор за тренирање ги користите П2, П3 и П4, додека за тестирање го
користите П1. Во секој чекор пресметајте ја точноста на моделот. Испечатете ја просечната точност од сите чекори.

Со поделбата на подмножества со која се добива највисока точност направете евалуација со отстранување на колона чиј
индекс се чита од стандарден влез. На пример: ако највисока точност се добива кога за тренирање се користат П1, П2 и П3,
а за тестирање П4 тогаш од ваквата верзија на подмножества за тренирање и тестирање ја отстранувате колоната. Повторно
извршете тренирање и евалуација на класификаторот. Испечатете ја неговата точност.

Од стандарден влез прво се чита името на класификаторот (model) кој треба да се евалуира (NB за наивен баесов
класификатор; MLP за невронска мрежа со 50 неврони, ReLU активациска функција и 0.001 рата на учење), а потоа и колона
која треба да се отстрани (col).

````
For example:
Input
NB
1

Result
Prosechna tochnost: 0.5584304476507584
Tochnost so otstraneta kolona: 0.6730769230769231
----------
Input
MLP
1

Result
Prosechna tochnost: 0.6289823984746293
Tochnost so otstraneta kolona: 0.8269230769230769
----------
Input
NB
2

Result
Prosechna tochnost: 0.5584304476507584
Tochnost so otstraneta kolona: 0.6730769230769231
----------
Input
MLP
2

Result
Prosechna tochnost: 0.6289823984746293
Tochnost so otstraneta kolona: 0.8269230769230769
----------
Input
NB
0

Result
Prosechna tochnost: 0.5584304476507584
Tochnost so otstraneta kolona: 0.6730769230769231
----------
Input
MLP
0

Result
Prosechna tochnost: 0.6289823984746293
Tochnost so otstraneta kolona: 0.8269230769230769
----------
Input
NB
3

Result
Prosechna tochnost: 0.5584304476507584
Tochnost so otstraneta kolona: 0.6730769230769231
----------
Input
MLP
3

Result
Prosechna tochnost: 0.6289823984746293
Tochnost so otstraneta kolona: 0.8269230769230769
----------
Input
NB
4

Result
Prosechna tochnost: 0.5584304476507584
Tochnost so otstraneta kolona: 0.6730769230769231
----------
Input
MLP
4

Result
Prosechna tochnost: 0.6289823984746293
Tochnost so otstraneta kolona: 0.8269230769230769
````

## Задача 9 - solar_flare_nn_mlpc_x_samples.py

Дадено ни е податочно множество за соларен одблесок. Сите атрибути кои ги содржи се од нумерички тип. Ваша задача е да
истренирате класификатор - невронска мрежа кој ќе предвидува класи на соларен одблесок. Од стандарден влез се чита
бројот на примероци X за кои треба да се направи предвидувањето. Последните X примероци се земаат за тестирање, додека
сите останати примероци се за тренирање (на пр. ако X=6, последните 6 примероци се тест примероци, а останатите
примероци се дел од тренирачкото множество).

Во почетниот код имате дадено податочно множество, како и објект од моделот MLPClassifier. Ваша задача е да го поделите
првичното податочно множество на множество за тренирање и множество за тестирање. Потоа, истренирајте го моделот.
Пресметајте прецизност и одзив на моделот со тестирачкото множество и вредностите испечатете ги на стандарден излез.
Напомена: Освен тоа што се бара не е потребно да имплементирате ништо друго!

прецизност = TP / (TP + FP)

одзив = TP / (TP + FN)

TP - број на точно предвидени позитивни класи

FP - број на грешно предвидени позитивни класи

TN - број на точно предвидени негативни класи

FN - број на грешно предвидени негативни класи

ЗАБЕЛЕШКА: Ако TP + FP е 0, тогаш вредноста за прецизноста е 0. Ако TP + FN е 0, тогаш вредноста за одзив е 0.

За да ги добиете истите резултати како и во тест примерите, при креирање на класификаторот поставете random_state=0

````
For example:
Input
100

Result
Precision: 0.7777777777777778
Recall: 0.625
----------
Input
150

Result
Precision: 0.7407407407407407
Recall: 0.47619047619047616
----------
Input
200

Result
Precision: 0.53
Recall: 1.0
----------
Input
50

Result
Precision: 0.75
Recall: 0.6
----------
Input
1

Result
Precision: 1.0
Recall: 1.0
----------
````

## Задача 10 - wine_quality_dtc_mlpc_scaler.py

Дадено е податочно множество со податоци за квалитет на вино. Податочното множетво е дефинирано во променливата dataset.
Последната колона ја содржи оценката за квалитетот на виното која може да има вредности помеѓу 0 и 10. Сите колони
содржат податоци од непрекинат тип.

Ваша задача е да истренирате класификатор кој ќе предвидува дали некое вино има добар или лош квалитет. Поделете ги
оценките од последната колона во две класи: 1 - добар квалитет и 0 - лош квалитет на следниот начин:

* вината што имаат оценка поголема или еднаква на 5 имаат добар квалитет
* вината што имаат оценка помала од 5 имаат лош квалитет

Првите X проценти од податочното множество се користат за тестирање, а останатите за тренирање. Делот од множеството што
треба да се користи за тестирање се чита од стандардниот влез.

Истренирајте дрво на одлука (criterion='gini') и најдете го атрибутот со најмала важност. Овој атрибут отстранете го од
податочното множество.

Потребно е да истренирајте модел на невронска мрежа со 15 неврони во скриениот слој, активациска функција (activation)
ReLU, рата на учење (learning_rate_init) 0.001 и 200 епохи (max_iter). Притоа користете го множеството од кое е
отстранета колоната на атрибутот со најмала важност. Ова множество дополнително скалирајте го со StandardScaler и
MinMaxScaler.

Потребно е да ги пресметате и испечатите точноста на класификаторот трениран со податоците скалирани со StandardScaler и
на класификаторот трениран со податоците скалирани со MinMaxScaler.

За да ги добиете истите резултати како и во тест примерите, при креирање на класификаторите поставете random_state=0.

````
For example:
Input
20

Result
Tocnost so StandardScaler: 0.8148148148148148
Tocnost so MinMaxScaler: 0.7407407407407407
----------
Input
10

Result
Tocnost so StandardScaler: 0.9230769230769231
Tocnost so MinMaxScaler: 0.7692307692307693
----------
Input
50

Result
Tocnost so StandardScaler: 0.7391304347826086
Tocnost so MinMaxScaler: 0.6956521739130435
----------
Input
70

Result
Tocnost so StandardScaler: 0.7422680412371134
Tocnost so MinMaxScaler: 0.6701030927835051
````

## оваа е следна Задача 11 - solar_flare_nbc_dtc_mlpc_x_samples.py 

Дадено ни е податочно множество за соларен одблесок. Сите атрибути кои ги содржи се од нумерички тип. Ваша задача е да
истренирате класификатор кој ќе предвидува класи на соларен одблесок. Од стандарден влез се чита бројот на примероци X
за кои треба да се направи предвидувањето. Првите X примероци се земаат за тестирање, додека сите останати примероци се
за тренирање (на пр. ако X=6, првите 6 примероци се тест примероци, а останатите примероци се дел од тренирачкото
множество).

Дополнително, од стандарден влез се чита информација за тип на класификатор кој треба да се изгради (DT - дрво на
одлука, NB - наивен баесов класификатор, NN - невронска мрежа). За невронската мрежа важи дека има 3 неврони во
скриениот слој, активациска функција activation='relu', рата на учење learning_rate_init=0.003, максимален број на
итерации max_iter=200. Изградете два класификатори од соодветен тип, со тоа што ќе изградите еден класификатор со сите
колони од тренирачкото множество и еден класификатор кај кој е отстранета една колона која се чита од стандарден влез.
На пример, ако од стандарден влез прочитате DT и индекс на колона 10 треба да изградите:

* дрво на одлука со верзија на множеството во која е отстранета колоната со индекс 10
* дрво на одлука со верзија на множеството во која се содржат сите колони

Пресметајте ја точноста на двата класификатори. Потоа пресметајте ја и прецизноста на класификаторот кој има поголема
точност. На стандарден излез испечатете кој класификатор има поголема точност ("Klasifiktorot so site koloni ima
pogolema tochnost", "Klasifikatorite imaat ista tochnost" или "Klasifiktorot so edna kolona pomalku ima pogolema
tochnost") и прецизноста на овој класификатор.

прецизност = TP / (TP + FP)

TP - број на точно предвиден соларен одблесок (true positive - класа = 1, предвидено е 1)

FP - број на грешно предвиден соларен одблесок (false positive - класа = 0, предвидено е 1)

````
For example:
Input
100
NB
3

Result
Klasifiktorot so site koloni ima pogolema tochnost
0.6774193548387096
----------
Input
10
DT
1

Result
Klasifikatorite imaat ista tochnost
1.0
----------
Input


Result

----------
Input


Result

----------
Input


Result

----------
Input


Result

----------
Input


Result

----------
Input


Result

----------
Input


Result

----------
Input


Result

````

## Задача 12 -

## Задача 13 -

## Задача 14 - glass_type_dtc.py

Дадено е податочно множество за класификација на тип на стакло. Податочното множество содржи 9 атрибути кои го
претставуваат хемискиот состав на стаклото (силикон, калиум, калциум, алуминиум, железо, итн.). Класниот атрибут го
претставува типот на стакло и има 7 вредности.

Податочното множество поделете го на подмножества за тренирање и тестирање така што првите N примероци ќе се користат за
тестирање, а останатите за тренирање. Со помош на класификатор - дрво на одлука со најмногу L листови одредете го
најважниот атрибут и отстранете го. Потоа скалирајте ги атрибутите со StandardScaler.

Потребно е да проверите како скалирањето на податоци влијае врз класификацијата на типот на стакло доколку се отстрани
најважниот атрибут. Направете класификатор - колекција од D дрва на одлука кои користат gini како критериум за избор на
најдобар атрибут за поделба. Тренирајте го класификаторот со оригиналното податочно множество и со множеството од кое е
отстранет најважниот атрибут, а останатите атрибути се скалирани. Потоа пресметајте ја точноста која се добива со
множеството за тестирање.

Од стандарден влез прво се чита вредноста N za бројот на примероци во множеството за тестирање. Потоа се читаат
вредноста L за максималниот број на листови и вредноста D за бројот на дрва на одлука.

На стандарден излез да се испечати точноста добиена со двата класификатори. Потоа да се испечати како скалирањето на
атрибути влијае врз точноста („Skaliranjeto na atributi ja podobruva tochnosta“, „Skaliranjeto na atributi ne ja
podobruva tochnosta“, или „Skaliranjeto na atributi nema vlijanie“).

За да ги добиете истите резултати како и во тест примерите, при креирање на класификаторите поставете random_state=0.

````
For example:
Input
100
50
70

Result
Tochnost so originalnoto podatochno mnozestvo: 0.66
Tochnost so skalirani atributi: 0.68
Skaliranjeto na atributi ja podobruva tochnosta
----------
Input
200
50
70

Result
Tochnost so originalnoto podatochno mnozestvo: 0.5
Tochnost so skalirani atributi: 0.525
Skaliranjeto na atributi ja podobruva tochnosta
----------
Input
100
20
70

Result
Tochnost so originalnoto podatochno mnozestvo: 0.66
Tochnost so skalirani atributi: 0.68
Skaliranjeto na atributi ja podobruva tochnosta
----------
Input
200
20
70

Result
Tochnost so originalnoto podatochno mnozestvo: 0.5
Tochnost so skalirani atributi: 0.525
Skaliranjeto na atributi ja podobruva tochnosta
----------
Input
100
50
5

Result
Tochnost so originalnoto podatochno mnozestvo: 0.69
Tochnost so skalirani atributi: 0.58
Skaliranjeto na atributi ne ja podobruva tochnosta
----------
Input
200
50
50

Result
Tochnost so originalnoto podatochno mnozestvo: 0.495
Tochnost so skalirani atributi: 0.515
Skaliranjeto na atributi ja podobruva tochnosta
----------
Input
200
20
10

Result
Tochnost so originalnoto podatochno mnozestvo: 0.46
Tochnost so skalirani atributi: 0.435
Skaliranjeto na atributi ne ja podobruva tochnosta
----------
Input
100
5
150

Result
Tochnost so originalnoto podatochno mnozestvo: 0.66
Tochnost so skalirani atributi: 0.67
Skaliranjeto na atributi ja podobruva tochnosta
----------
Input
5
5
5

Result
Tochnost so originalnoto podatochno mnozestvo: 0.8
Tochnost so skalirani atributi: 0.8
Skaliranjeto na atributi nema vlijanie
````

## Задача 15 - nbc_dtc_rfc_mlpc.py

Дадено е податочно множество во променливата dataset. Последната колона ја претставува класата (0 или 1). Сите атрибути
кои ги содржи се од нумерички тип.

Потребно е да направите 4 модели на класификација:

* Наивен баесов класификатор.
* Дрво на одлука со ентропија како критериум за избор на најдобар атрибут за поделба.
* Класификатор со колекција од 4 дрва на одлука со ентропија како критериум за избор на најдобар атрибут за поделба.
* Невронска мрежа со 10 неврони, ReLU активациска функција, 0.001 рата на учење.

Од стандарден влез се чита процентот на примероци за поделба. Првите X% од секоја класа се земаат за тренирање, додека
останатите примероци се за тестирање.

Изградете ги моделите на класификација и одредете кој од нив има најголема точност. На стандарден излез испечатете кој е
класификаторот со најголема точност. (Najgolema tocnost ima klasifikatorot Naive Bayes/Decision Tree/Random Forest/MLP)

Потоа изградете уште еден модел за класификација со колекција на класификатори на следниот начин:

Класификаторот кој има најголема точност има тежина на глас 2 (класата која ја предвидува класификаторот со најголема
точност добива 2 гласа)
Сите останати класификатори имаат тежина на глас 1
За предвидена се смета класата која што ќе добие најголем број гласови
На пример, ако класификаторот со најголема точност и уште еден класификатор ја предвидат класата 0, а останатите два
класификатори ја предвидат класата 1, тогаш класата 0 ќе има 3 гласа, а класата 1 ќе има 2 гласа. Класификаторот ја
предвидува класата 0.
Пресметајте и испечатете го одзивот на овој модел (колекцијата од класификатори).

одзив = TP / (TP + FN)

TP - број на точно предвидени позитивни класи

FP - број на грешно предвидени позитивни класи

TN - број на точно предвидени негативни класи

FN - број на грешно предвидени негативни класи

````
For example:
Input
70

Result
Najgolema tocnost ima klasifikatorot Random Forest
Odzivot na kolekcijata so klasifikatori e 1.0
----------
Input
80

Result
Najgolema tocnost ima klasifikatorot Random Forest
Odzivot na kolekcijata so klasifikatori e 1.0
----------
Input
60

Result
Najgolema tocnost ima klasifikatorot Naive Bayes
Odzivot na kolekcijata so klasifikatori e 0.9
----------
Input
90

Result
Najgolema tocnost ima klasifikatorot Naive Bayes
Odzivot na kolekcijata so klasifikatori e 1.0
````

## Задача 16 - wdbc_nn_mlpc.py

Дадено е податочноto множество Wisconsin Diagnostic Breast Cancer (WDBC). Карактеристиките се пресметани од
дигитализирана слика на рак, со што се опишуваат карактеристиките на јадрото на клетката присутна на сликата. Потребно е
да се направи модел на невронска мрежа кој ќе детектира малигнен рак (B = benign, M = malignant). Класата е дадена како
прв елемент, по што следуваат карактеристиките. Направете мапирање на класите така што класата B ќе ја претставите како
0, а класата M како 1.

Поделете го податочното множество на тренирачко и тестирачко множество со односот 70%:30% од секоја од класите (првите
70% од класата 'M' и првите 70% од класата 'B' се дел од тренирачкото множество, а останатите податочни примероци се дел
од тестирачкото множество). При изградба на тренирачкото множество почнете од класата 'M'. Карактеристиките потребно е
да се нормализираат со MinMaxScaler во ранг од -1 до 1. Изградете невронска мрежа чиј што број на неврони во скриениот
слој се чита од стандарден влез. Моделот се тренира со рата на учење од 0.001, 20 епохи и ReLU активациска функција на
невроните од скриениот слој.

Потребно е да се пресметаат прецизноста и одзивот кои се добиваат со тренирачкото множество и со тестирачкото множество.

прецизност = TP / (TP + FP)

одзив = TP / (TP + FN)

TP - број на точно предвидени малигни клетки

FP - број на грешно предвидени малигни клетки

TN - број на точно предвидени бенигни клетки

FN - број на грешно предвидени бенигни клетки

Напомена: За да се постави рангот на карактеристиките од -1 до 1, употребете го атрибутот feature_range од класата
MinMaxScaler.

````
For example:
Input
20

Result
Preciznost so trenirachkoto mnozhestvo: 0.9615384615384616
Odziv so trenirachkoto mnozhestvo: 0.5067567567567568
Preciznost so testirachkoto mnozhestvo: 1.0
Odziv so testirachkoto mnozhestvo: 0.640625
----------

````

## Задача 17 - voting_based_classification_dtc.py

Да се изградат три дрва на одлука со даденото множество за тренирање, така што првото дрво на одлука ќе се тренира со
првите 30% од множеството, второто дрво со следните 30%, а третото дрво ќе ги користи останатите 40% од примероците за
тренирање. Потребно е да се предвиди класата на даден тест примерок кој се чита од стандарден влез. Предвидувањето на
класата се врши со метод на гласање, каде што секој од трите дрва на одлука дава глас за класата која ја предвидува.

За предвидување се зема класата која има најголем број на гласови и се печати на излез. Доколку постојат две или повеќе
класи со ист број на максимални гласови се печати 'unknown' како предвидена класа.

````
Input
6.7, 3.0, 5.2, 2.3, 0

Expected
Glasovi: {0: 3, 1: 0, 2: 0}
Predvidena klasa: 0
````

## Задача 18 - solar_flare_comparing_nn_mlpc.py

Дадено ни е податочно множество за соларен одблесок. Сите атрибути кои ги содржи се од нумерички тип. Ваша задача е да
истренирате класификатор - невронска мрежа кој ќе предвидува класи на соларен одблесок. Од стандарден влез се чита
бројот на примероци X за кои треба да се направи предвидувањето. Првите X примероци се земаат за тестирање, додека сите
останати примероци се за тренирање (на пр. ако X=6, првите 6 примероци се тест примероци, а останатите примероци се дел
од тренирачкото множество).

Во почетниот код имате дадено податочно множество, како и објект од моделот MLPClassifier. Ваша задача е да го поделите
првичното податочно множество на множество за тренирање и множество за тестирање. Потоа, истренирајте го моделот.
Пресметајте точност на моделот со тестирачкото множество и вредноста испечатете ја на стандарден излез.

Потоа, од стандарден влез се чита нова вредност за бројот на примероци X2 за кои треба да се направи предвидувањето.
Првите X2 примероци се земаат за тестирање, додека сите останати примероци се за тренирање (на пр. ако X2=6, првите 6
примероци се тест примероци, а останатите примероци се дел од тренирачкото множество). Поделете го првичното податочно
множество според X2 на множество за тренирање и множество за тестирање.

Направете втор модел (MLPClassifier) со истите параметри како првиот. Истренирајте го овој модел и пресметајте точност
со тестирачкото множество и вредноста испечатете ја на стандарден излез.

На крај, испечатете кој модел има поголема точност. ('Prviot model ima pogolema tochnost', 'Vtoriot model ima pogolema
tochnost', 'Dvata modeli imaat ednakva tochnost')

Напомена: Освен тоа што се бара не е потребно да имплементирате ништо друго!

````
Input
100
10

Expected
Tochnost model1: 0.78
Tochnost model2: 0.7
Prviot model ima pogolema tochnost
````

## Задачи за вежбање за втор колоквиум - 7, 11, 12, 13
## Машинско учење 2 - 1, 2, 3
## Дополнителна лабораториска вежба - втор колоквиум - 1, 2
## Информирано пребарување - snake
## Проблеми кои исполнуваат услови - 5
## 
